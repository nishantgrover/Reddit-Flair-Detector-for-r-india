{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dependencies\n",
    "import pandas as pd\n",
    "from joblib import dump\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the cleaned extracted posts data\n",
    "posts = pd.read_csv('../Data/cleaned_scrapedData.csv')\n",
    "allFlairs=['AMA', 'AskIndia', 'Business/Finance', 'Coronavirus', 'Food', 'Non-Political', 'Photography', 'Policy/Economy', 'Politics', 'Scheduled', 'Science/Technology', 'Sports', '[R]eddiquette']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining some models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes Model\n",
    "def modelTrainMNB(train_X, train_Y, test_X, test_Y):\n",
    "    NBClassifier = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('nb',MultinomialNB())])\n",
    "    NBClassifier.fit(train_X, train_Y)\n",
    "    predicted_Y = NBClassifier.predict(test_X)\n",
    "    print(classification_report(test_Y, predicted_Y,target_names=allFlairs))\n",
    "    print(\"Accuracy : \", accuracy_score(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-layer Perceptron Model\n",
    "def modelTrainMLP(train_X, train_Y, test_X, test_Y):\n",
    "    MLP = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('mlp',MLPClassifier(hidden_layer_sizes=(30,30,30), activation='relu'))])\n",
    "    MLP.fit(train_X, train_Y)\n",
    "    predicted_Y = MLP.predict(test_X)\n",
    "    print(classification_report(test_Y, predicted_Y,target_names=allFlairs))\n",
    "    print(\"Accuracy : \", accuracy_score(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "def modelTrainRNF(train_X, train_Y, test_X, test_Y):\n",
    "    RNF = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('rnf',RandomForestClassifier(n_estimators=1000, random_state=42))])\n",
    "    RNF.fit(train_X, train_Y)\n",
    "    predicted_Y = RNF.predict(test_X)\n",
    "    print(classification_report(test_Y, predicted_Y,target_names=allFlairs))\n",
    "    print(\"Accuracy : \", accuracy_score(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "def modelTrainLR(train_X, train_Y, test_X, test_Y):\n",
    "    LR = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('lr', LogisticRegression(penalty='l2',random_state=10, solver='lbfgs', multi_class='multinomial'))])\n",
    "    LR.fit(train_X, train_Y)\n",
    "    predicted_Y = LR.predict(test_X)\n",
    "    print(classification_report(test_Y, predicted_Y,target_names=allFlairs))\n",
    "    print(\"Accuracy : \", accuracy_score(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear SVM Model\n",
    "def modelTrainLSVM(train_X, train_Y, test_X, test_Y):\n",
    "    LR = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('linear_svc', LinearSVC(penalty='l2',C=1.0))])\n",
    "    LR.fit(train_X, train_Y)\n",
    "    predicted_Y = LR.predict(test_X)\n",
    "    print(classification_report(test_Y, predicted_Y,target_names=allFlairs))\n",
    "    print(\"Accuracy : \", accuracy_score(test_Y, predicted_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert into string datatype\n",
    "def makeString(text):\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting relevant attribute values into string datatype\n",
    "posts['author'] = posts['author'].apply(makeString)\n",
    "posts['body'] = posts['body'].apply(makeString)\n",
    "posts['comments'] = posts['comments'].apply(makeString)\n",
    "posts['flair'] = posts['flair'].apply(makeString)\n",
    "posts['title'] = posts['title'].apply(makeString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the test data for the combination url-author-title-body-comments\n",
    "train={}\n",
    "train[\"url-author-title-body-comments\"]=[]\n",
    "flairsList=[]\n",
    "for i in range(len(posts['url'])):\n",
    "    flairsList.append(posts['flair'][i])\n",
    "    train[\"url-author-title-body-comments\"].append(posts['url'][i] +posts['author'][i] + ' ' + posts['title'][i] + ' ' + posts['body'][i]+' '+posts['comments'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the data on every model and checking for the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: url-author-title-body-comments\n",
      "\n",
      "\n",
      " Multinomial Naive Bayes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.40      1.00      0.58        17\n",
      "          AskIndia       0.30      0.39      0.34        18\n",
      "  Business/Finance       0.64      0.39      0.48        18\n",
      "       Coronavirus       0.41      1.00      0.58        21\n",
      "              Food       0.82      0.53      0.64        17\n",
      "     Non-Political       0.00      0.00      0.00        21\n",
      "       Photography       0.95      0.71      0.82        28\n",
      "    Policy/Economy       0.68      0.65      0.67        20\n",
      "          Politics       0.60      0.52      0.56        23\n",
      "         Scheduled       0.62      1.00      0.77        18\n",
      "Science/Technology       0.67      0.08      0.15        24\n",
      "            Sports       0.91      0.56      0.69        18\n",
      "     [R]eddiquette       0.42      0.47      0.44        17\n",
      "\n",
      "          accuracy                           0.55       260\n",
      "         macro avg       0.57      0.56      0.52       260\n",
      "      weighted avg       0.58      0.55      0.52       260\n",
      "\n",
      "Accuracy :  0.5538461538461539\n",
      "\n",
      "\n",
      " Multi-layer Perceptron\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.93      0.76      0.84        17\n",
      "          AskIndia       0.22      0.56      0.32        18\n",
      "  Business/Finance       0.60      0.33      0.43        18\n",
      "       Coronavirus       0.38      0.71      0.49        21\n",
      "              Food       0.92      0.71      0.80        17\n",
      "     Non-Political       0.00      0.00      0.00        21\n",
      "       Photography       0.88      0.82      0.85        28\n",
      "    Policy/Economy       0.43      0.60      0.50        20\n",
      "          Politics       0.60      0.26      0.36        23\n",
      "         Scheduled       0.95      1.00      0.97        18\n",
      "Science/Technology       0.40      0.33      0.36        24\n",
      "            Sports       0.80      0.67      0.73        18\n",
      "     [R]eddiquette       0.33      0.24      0.28        17\n",
      "\n",
      "          accuracy                           0.53       260\n",
      "         macro avg       0.57      0.54      0.53       260\n",
      "      weighted avg       0.57      0.53      0.53       260\n",
      "\n",
      "Accuracy :  0.5346153846153846\n",
      "\n",
      "\n",
      " Random Forest\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.68      1.00      0.81        17\n",
      "          AskIndia       0.30      0.44      0.36        18\n",
      "  Business/Finance       0.41      0.39      0.40        18\n",
      "       Coronavirus       0.53      0.76      0.63        21\n",
      "              Food       0.67      0.71      0.69        17\n",
      "     Non-Political       0.20      0.10      0.13        21\n",
      "       Photography       0.67      0.86      0.75        28\n",
      "    Policy/Economy       0.67      0.40      0.50        20\n",
      "          Politics       0.47      0.39      0.43        23\n",
      "         Scheduled       0.86      1.00      0.92        18\n",
      "Science/Technology       0.61      0.58      0.60        24\n",
      "            Sports       0.67      0.67      0.67        18\n",
      "     [R]eddiquette       0.50      0.12      0.19        17\n",
      "\n",
      "          accuracy                           0.57       260\n",
      "         macro avg       0.56      0.57      0.54       260\n",
      "      weighted avg       0.56      0.57      0.55       260\n",
      "\n",
      "Accuracy :  0.573076923076923\n",
      "\n",
      "\n",
      " Logistic Regression\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       1.00      0.94      0.97        17\n",
      "          AskIndia       0.37      0.39      0.38        18\n",
      "  Business/Finance       0.60      0.67      0.63        18\n",
      "       Coronavirus       0.47      0.81      0.60        21\n",
      "              Food       0.79      0.88      0.83        17\n",
      "     Non-Political       0.50      0.14      0.22        21\n",
      "       Photography       0.87      0.93      0.90        28\n",
      "    Policy/Economy       0.60      0.60      0.60        20\n",
      "          Politics       0.55      0.48      0.51        23\n",
      "         Scheduled       0.95      1.00      0.97        18\n",
      "Science/Technology       0.65      0.71      0.68        24\n",
      "            Sports       0.93      0.78      0.85        18\n",
      "     [R]eddiquette       0.64      0.53      0.58        17\n",
      "\n",
      "          accuracy                           0.68       260\n",
      "         macro avg       0.69      0.68      0.67       260\n",
      "      weighted avg       0.68      0.68      0.67       260\n",
      "\n",
      "Accuracy :  0.6807692307692308\n",
      "\n",
      "\n",
      " Linear Support Vector Machine\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "               AMA       0.94      1.00      0.97        17\n",
      "          AskIndia       0.42      0.44      0.43        18\n",
      "  Business/Finance       0.57      0.67      0.62        18\n",
      "       Coronavirus       0.53      0.81      0.64        21\n",
      "              Food       0.82      0.82      0.82        17\n",
      "     Non-Political       0.40      0.19      0.26        21\n",
      "       Photography       0.81      0.93      0.87        28\n",
      "    Policy/Economy       0.53      0.45      0.49        20\n",
      "          Politics       0.55      0.48      0.51        23\n",
      "         Scheduled       0.90      1.00      0.95        18\n",
      "Science/Technology       0.65      0.62      0.64        24\n",
      "            Sports       0.88      0.78      0.82        18\n",
      "     [R]eddiquette       0.60      0.53      0.56        17\n",
      "\n",
      "          accuracy                           0.67       260\n",
      "         macro avg       0.66      0.67      0.66       260\n",
      "      weighted avg       0.66      0.67      0.66       260\n",
      "\n",
      "Accuracy :  0.6692307692307692\n"
     ]
    }
   ],
   "source": [
    "# segregating test and train data\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(train[\"url-author-title-body-comments\"], flairsList, test_size=0.1, random_state=42)\n",
    "print(\"features: url-author-title-body-comments\")\n",
    "\n",
    "# training on each model defined above\n",
    "print(\"\\n\\n Multinomial Naive Bayes\")\n",
    "modelTrainMNB(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "print(\"\\n\\n Multi-layer Perceptron\")\n",
    "modelTrainMLP(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "print(\"\\n\\n Random Forest\")\n",
    "modelTrainRNF(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "print(\"\\n\\n Logistic Regression\")\n",
    "modelTrainLR(train_X, train_Y, test_X, test_Y)\n",
    "\n",
    "print(\"\\n\\n Linear Support Vector Machine\")\n",
    "modelTrainLSVM(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Model/finalModel.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(train[\"url-author-title-body-comments\"], flairsList, test_size=0.1, random_state=42)\n",
    "# making the final model\n",
    "finalModel_LR = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('lr', LogisticRegression(penalty='l2',random_state=10, solver='lbfgs', multi_class='multinomial'))])\n",
    "finalModel_LR.fit(train_X, train_Y)\n",
    "#dumping the final model\n",
    "dump(finalModel_LR, '../Model/finalModel.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
